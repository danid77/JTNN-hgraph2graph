{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import csv\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from random import random\n",
    "import traceback\n",
    "import rdkit\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import math, random, sys\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('/home/lnptest/SB_jin/git_test/hgraph2graph_wandb/')\n",
    "from hgraph import *\n",
    "from hgraph import vocab2\n",
    "import rdkit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "def setup_logging():\n",
    "    logging.basicConfig(\n",
    "        level=logging.DEBUG,\n",
    "        format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "        handlers=[logging.FileHandler('output.log'), logging.StreamHandler()]\n",
    "    )\n",
    "    lg = rdkit.RDLogger.logger()\n",
    "    lg.setLevel(rdkit.RDLogger.CRITICAL)\n",
    "\n",
    "# argparse 대신 직접 args 설정\n",
    "class Args:\n",
    "    vocab = \"vocab.txt\"\n",
    "    atom_vocab = common_atom_vocab\n",
    "    model = \"/home/lnptest/SB_jin/git_test/hgraph2graph_wandb/ckpt/chembl-240627-2/model_95232.ckpt\"\n",
    "    seed = 7\n",
    "    nsample = 10000000\n",
    "    rnn_type = 'LSTM'\n",
    "    hidden_size = 512\n",
    "    embed_size = 512\n",
    "    batch_size = 50\n",
    "    latent_size = 32\n",
    "    depthT = 15\n",
    "    depthG = 15\n",
    "    diterT = 1\n",
    "    diterG = 3\n",
    "    dropout = 0.0\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments():\n",
    "    parser = argparse.ArgumentParser(description='Description of your program')\n",
    "    parser.add_argument(\"-s\", \"--sample\", required=True, help=\"Number of samples to generate\", type=int)\n",
    "    parser.add_argument(\"-i\", \"--ideacode\", required=True, help=\"Ideacode for the query\", type=str)\n",
    "    parser.add_argument(\"-o\", \"--output_dir\", default=\"/home/dwpdp/ideadb/data/\", help=\"Directory to save the result\", type=str)\n",
    "    parser.add_argument(\"-t\", \"--temp_suffix\", default=\"\", help=\"Temporary suffix for the output file\", type=str)\n",
    "    return parser.parse_args("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(sampled_dict, args, execution_time):\n",
    "    output_dir_path = os.path.join(args.output_dir, args.ideacode, 'hgraph')\n",
    "    os.makedirs(output_dir_path, exist_ok=True)\n",
    "    result_file_name = f'Gen_result_{args.ideacode}{args.temp_suffix}.csv'\n",
    "    result_file_path = os.path.join(output_dir_path, result_file_name)\n",
    "    try:\n",
    "        with open(result_file_path, 'w', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            csv_writer.writerow([\"Query_ID\", \"Gen_SMILE\", \"Gen_ID\", \"Sim(ECFP4)\"])\n",
    "            for idx, (gen_smi, ecfp_sim) in enumerate(sampled_dict.items()):\n",
    "                gen_id = f\"{args.ideacode}-S{str(idx + 1).zfill(3)}\"\n",
    "                csv_writer.writerow([args.ideacode, gen_smi, gen_id, f\"{ecfp_sim:.3f}\"])\n",
    "            \n",
    "            # 실행 시간을 기록합니다.\n",
    "            hours = int(execution_time / 3600)\n",
    "            minutes = int((execution_time % 3600) / 60)\n",
    "            seconds = int((execution_time % 3600) % 60)\n",
    "            csv_writer.writerow([])\n",
    "            csv_writer.writerow([f\"Execution time: {hours}h {minutes}m {seconds}s\"])\n",
    "        logging.info('Generation complete')\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to write results: {e}\")\n",
    "\n",
    "def main():\n",
    "    setup_logging()\n",
    "    args = parse_arguments()\n",
    "    model = initialize_model()\n",
    "\n",
    "    query_path = f'{args.ideacode}.smi'\n",
    "    with open(query_path, 'r') as f:\n",
    "        query_smi = f.readline().strip()\n",
    "\n",
    "    query_mol = Chem.MolFromSmiles(query_smi)\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "    start_time = time.time()\n",
    "\n",
    "    sampled_dict = {}\n",
    "    sampled_list = []\n",
    "\n",
    "    while len(sampled_list) < args.sample:\n",
    "        try:\n",
    "            gen_smi = model.reconstruct_scaled(query_smi, scale=random(), prob_decode=False, debug=False)\n",
    "        except IndexError as e:\n",
    "            logging.error(f\"IndexError: {e}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Unexpected error: {e}, Traceback: {traceback.format_exc()}\")\n",
    "            continue\n",
    "\n",
    "        if not gen_smi:\n",
    "            continue\n",
    "\n",
    "        gen_smi = Chem.MolToSmiles(Chem.MolFromSmiles(gen_smi))\n",
    "        gen_mol = Chem.MolFromSmiles(gen_smi)\n",
    "        if gen_mol is None:  \n",
    "            continue\n",
    "\n",
    "        # ECFP4 계산\n",
    "        fps_query_ecfp = AllChem.GetMorganFingerprintAsBitVect(query_mol, 2, nBits=1024)\n",
    "        fps_gen_ecfp = AllChem.GetMorganFingerprintAsBitVect(gen_mol, 2, nBits=1024)\n",
    "\n",
    "        similarity_ecfp = DataStructs.FingerprintSimilarity(fps_query_ecfp, fps_gen_ecfp)\n",
    "\n",
    "        # 유사도가 기준치 이상인 SMILES만 저장\n",
    "        if similarity_ecfp >= 0.1:  # 기준치는 필요에 따라 조정하시면 됩니다.\n",
    "            if gen_smi not in sampled_dict:\n",
    "                sampled_dict[gen_smi] = similarity_ecfp\n",
    "                sampled_list.append(gen_smi)\n",
    "\n",
    "                # 생성 과정시 모니터링 용도로 화면에 출력하는 부분으로 추후 삭제 가능합니다.             \n",
    "                print(f'succeed >> {gen_smi}, {len(sampled_list)}, {similarity_ecfp:.3f}')\n",
    "\n",
    "        if len(sampled_list) >= args.sample:\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    write_results(sampled_dict, args, execution_time)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n",
    "# rd_python JTNN_generator.py -s 10 -i IDEA0138008"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jtnn_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
